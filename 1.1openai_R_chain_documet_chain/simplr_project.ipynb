{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd293a2",
   "metadata": {},
   "source": [
    "## simple Gen AI project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4beaab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "#used for Langsmith tracking\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafc066",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Ingestion--From the website we need to scrape the data\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/tutorials/Administrators/manage_spend\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e913ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data--> Docs-->Divide our Docuemnts into chunks dcouments-->text-->vectors-->Vector Embeddings--->Vector Store DB\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=50)\n",
    "Documets=text_splitter.split_documents(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a54b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding=OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc073f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectore_store_db=FAISS.from_documents(Documets,embedding)\n",
    "vectore_store_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query From a vector db\n",
    "query=\"LangSmith has two usage limits: total traces and extended\"\n",
    "result=vectore_store_db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607725f6",
   "metadata": {},
   "source": [
    "## Retrivel chain\n",
    "- Retrieval Chain is a pattern used to build an LLM-powered Q&A system that can search and answer from your own data, like PDFs, websites, Notion docs, or databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieval chain , Docment chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate(\n",
    "    \"\"\"Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    " \"\"\"\n",
    " )\n",
    "Documet_chain=create_stuff_documents_chain(\n",
    "    llm,prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "Documet_chain.invoke({\n",
    "    \"input\":\"LangSmith has two usage limits: total traces and extended\",\n",
    "    \"context\":[Document(page_content=\"LangSmith has two usage limits: total traces and extended traces. These correspond to the two metrics we've been tracking on our usage graph. \")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb53f1",
   "metadata": {},
   "source": [
    "However, we want the documents to first come from the retriever we just set up. That way, we can use the retriever to dynamically select the most relevant documents and pass those in for a given question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input--->Retriever--->vectorstoredb\n",
    "\n",
    "vectore_store_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver=vectore_store_db.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriver,Documet_chain)\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the responce from the llm\n",
    "responce=retrieval_chain.invoke({'input':\"LangSmith has two usage limits: total traces and extended\"})\n",
    "responce['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88026c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
